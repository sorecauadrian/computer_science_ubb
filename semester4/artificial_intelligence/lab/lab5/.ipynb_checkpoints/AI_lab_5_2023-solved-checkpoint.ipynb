{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5ee7e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer: 2 neurons\n",
    "# hidden layer: 32 neurons\n",
    "# output layer: 2 neurons\n",
    "# sigmoid activation -> sigmoid activation\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_net', nn.Linear(2,32)),\n",
    "    ('hidden_act', nn.Sigmoid()),\n",
    "    ('output_net', nn.Linear(32,2)),\n",
    "    ('output_act', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "# input layer: 2 neurons\n",
    "# hidden layer: 8 neurons\n",
    "# output layer: 2 neurons\n",
    "# relu activation -> sigmoid activation\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_net', nn.Linear(2,8)),\n",
    "    ('hidden_act', nn.ReLU()),\n",
    "    ('output_net', nn.Linear(8,2)),\n",
    "    ('output_act', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "# input layer: 2 neurons\n",
    "# hidden layer: 16 neurons\n",
    "# output layer: 2 neurons\n",
    "# sigmoid activation -> sigmoid activation\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden_net', nn.Linear(2,16)),\n",
    "    ('hidden_act', nn.Sigmoid()),\n",
    "    ('output_net', nn.Linear(16,2)),\n",
    "    ('output_act', nn.Sigmoid())\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden_net): Linear(in_features=2, out_features=32, bias=True)\n",
      "  (hidden_act): Sigmoid()\n",
      "  (output_net): Linear(in_features=32, out_features=2, bias=True)\n",
      "  (output_act): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden_net): Linear(in_features=2, out_features=8, bias=True)\n",
      "  (hidden_act): ReLU()\n",
      "  (output_net): Linear(in_features=8, out_features=2, bias=True)\n",
      "  (output_act): Sigmoid()\n",
      ")\n",
      "Sequential(\n",
      "  (hidden_net): Linear(in_features=2, out_features=16, bias=True)\n",
      "  (hidden_act): Sigmoid()\n",
      "  (output_net): Linear(in_features=16, out_features=2, bias=True)\n",
      "  (output_act): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)\n",
    "print(model2)\n",
    "print(model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# input data\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float)\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# expected output data\n",
    "data_target = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float)\n",
    "print(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions:\n",
    "### model 1: nn.MSELoss() - Mean Squared Error Loss; it calculates the mean squared difference between the predicted and target outputs\n",
    "### model 2: nn.CrossEntropyLoss() - suitable for multi-class classification problems.\n",
    "### model 3: nn.L1Loss() - Mean Absolute Error Loss; it calculates the mean absolute difference between the predicted and targe outputs\n",
    "\n",
    "# optimizers:\n",
    "### model 1: Adam\n",
    "### model 2: SGD (Stochastic Gradient Descent) \n",
    "### model 3: SGD\n",
    "\n",
    "criterion1 = nn.MSELoss()\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(), lr=0.01)\n",
    "criterion3 = nn.L1Loss()\n",
    "optimizer3 = torch.optim.SGD(model3.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cde91f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, criterion, optimizer):\n",
    "    for epoch in range(1000):\n",
    "        # clears the gradients of all optimized tensors\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # computes the loss by comparing the model's predictions (model(inputs)) with the actual outputs (outputs)\n",
    "        loss = criterion(model(inputs), outputs)\n",
    "\n",
    "        # computes gradients of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # updates the model parameters based on the gradients computed previously\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5b54cd8e-a1fa-4b04-a644-0d213bfad922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n",
      "Training Accuracy: 100.0\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "Training Accuracy: 62.5\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]])\n",
      "Training Accuracy: 62.5\n"
     ]
    }
   ],
   "source": [
    "for model in [model1, model2, model3]:\n",
    "    if model == model1:\n",
    "        criterion = criterion1\n",
    "        optimizer = optimizer1\n",
    "    if model == model2:\n",
    "        criterion = criterion2\n",
    "        optimizer = optimizer2\n",
    "    if model == model3:\n",
    "        criterion = criterion3\n",
    "        optimizer = optimizer3\n",
    "    train(model, data_in, data_target, criterion, optimizer)\n",
    "    outputs = model(data_in)\n",
    "    predicted = (outputs >= 0.5).float()\n",
    "    print(predicted)\n",
    "    accuracy = (predicted == data_target).float().mean()\n",
    "    print(f'Training Accuracy: {accuracy.item()*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "102fc259-3cf6-41d8-99d2-7d0ccf62b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of network1 :\n",
      " Parameter containing:\n",
      "tensor([[-3.1552, -3.2936],\n",
      "        [-1.1754, -2.2005],\n",
      "        [-3.4678, -3.2380],\n",
      "        [-2.0731, -2.4404],\n",
      "        [-2.3335, -1.8294],\n",
      "        [-2.1288, -2.5405],\n",
      "        [-3.5101, -3.6082],\n",
      "        [ 3.3369,  3.2557],\n",
      "        [ 3.8484,  3.5895],\n",
      "        [-4.0010,  3.2595],\n",
      "        [-1.3552, -2.2227],\n",
      "        [ 3.2408,  2.5292],\n",
      "        [-1.7415, -1.9035],\n",
      "        [-1.5948, -1.9520],\n",
      "        [-2.0701, -1.8737],\n",
      "        [ 2.6221,  2.8616],\n",
      "        [ 4.1168, -3.5127],\n",
      "        [-3.6282,  4.0629],\n",
      "        [ 0.7353,  1.6467],\n",
      "        [ 2.6038,  2.8151],\n",
      "        [ 2.3472,  2.3207],\n",
      "        [ 2.1848,  2.5888],\n",
      "        [ 2.5195,  2.7209],\n",
      "        [-2.2776, -2.6027],\n",
      "        [-1.9401, -1.3230],\n",
      "        [-2.5148, -2.6265],\n",
      "        [ 2.4218,  2.9244],\n",
      "        [ 3.4676,  3.3351],\n",
      "        [-3.7902, -3.9618],\n",
      "        [-2.0845, -2.0767],\n",
      "        [ 3.1833,  3.0574],\n",
      "        [-2.8940, -2.3587]], requires_grad=True)\n",
      "Weight of network2 :\n",
      " Parameter containing:\n",
      "tensor([[-0.6006, -0.2901],\n",
      "        [-0.6550,  0.5518],\n",
      "        [ 0.5047, -0.3856],\n",
      "        [ 0.2934,  0.1113],\n",
      "        [-0.4055,  0.1670],\n",
      "        [ 0.4743,  0.3016],\n",
      "        [-0.6502, -0.3254],\n",
      "        [-0.7110,  0.1865]], requires_grad=True)\n",
      "Weight of network3 :\n",
      " Parameter containing:\n",
      "tensor([[-0.4844, -0.6011],\n",
      "        [-0.3243, -0.6781],\n",
      "        [ 0.1906,  0.3236],\n",
      "        [ 0.0779, -0.5147],\n",
      "        [ 0.3867,  0.2194],\n",
      "        [ 0.2179,  0.4290],\n",
      "        [-0.1056, -0.1505],\n",
      "        [-0.0251,  0.0611],\n",
      "        [-0.3393, -0.2446],\n",
      "        [ 0.4535, -0.6731],\n",
      "        [ 0.2290,  0.4989],\n",
      "        [-0.3449, -0.5085],\n",
      "        [-0.5269, -0.3277],\n",
      "        [ 0.6698, -0.5332],\n",
      "        [ 0.5566,  0.6669],\n",
      "        [-0.1032,  0.1313]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('Weight of network1 :\\n',model1[0].weight)\n",
    "print('Weight of network2 :\\n',model2[0].weight)\n",
    "print('Weight of network3 :\\n',model3[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a0680-8527-4931-909c-5c414a7ddf35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
