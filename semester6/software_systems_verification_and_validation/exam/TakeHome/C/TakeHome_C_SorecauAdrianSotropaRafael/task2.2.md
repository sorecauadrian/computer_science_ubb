## Task 2 – Șotropa Rafael-Konstantinos

**Title:** *Software Testing of Generative AI Systems: Challenges and Opportunities*  
**Conference:** ICSE 2023 (International Conference on Software Engineering) – Future of Software Engineering (FoSE) Track  
**Author:** Aldeida Aleti  
**DOI:** 10.1109/FOSE56992.2023.00007

**Aim of the Research Study**  
This paper explores the unique challenges presented by generative AI systems in the context of software testing. It aims to identify the limitations of traditional testing methods when applied to generative models and to propose directions for future research in this area.

**Methodology of the Study**  
The author conducts a comprehensive literature review and analysis of current testing practices for generative AI systems. The study examines case studies and existing tools to assess their effectiveness in validating the outputs of generative models.

**Results**  
The analysis reveals that traditional testing techniques struggle with the non-deterministic and creative outputs of generative AI systems. Issues such as the lack of a clear oracle, difficulty in defining correctness, and the vastness of possible outputs pose significant testing challenges.

**Implication for Research and for Practice**  
For the research community, the paper highlights the need to develop new testing frameworks and metrics tailored to the characteristics of generative AI. Practitioners are advised to consider hybrid approaches that combine automated testing with human evaluation to effectively assess generative outputs.
